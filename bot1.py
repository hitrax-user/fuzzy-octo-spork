import logging
import re
import os
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import gspread
from oauth2client.service_account import ServiceAccountCredentials

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

log_path = os.path.join(os.path.dirname(__file__), "bot.log")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_path, mode="a", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger()
logger.setLevel(logging.INFO)  # —Ö–æ—Ç–∏–º –≤–∏–¥–µ—Ç—å —Å–≤–æ–∏ INFO-—Å–æ–æ–±—â–µ–Ω–∏—è

# ¬´–ó–∞–≥–ª—É—à–∏–º¬ª —à—É–º–Ω—ã–µ –ª–æ–≥–∏ httpx, httpcore, telegram.request
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("telegram.request").setLevel(logging.WARNING)
logging.info("üî• –õ–æ–≥–≥–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ. –õ–æ–≥-—Ñ–∞–π–ª: %s", log_path)
print("üìÇ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∑–∞–ø—É—Å–∫–∞:", os.getcwd())
print("üìÑ –û–∂–∏–¥–∞–µ–º—ã–π –ª–æ–≥-—Ñ–∞–π–ª:", log_path)

# Google Sheets
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("credentials.json", scope)
client = gspread.authorize(creds)
sheet = client.open_by_url(
    "https://docs.google.com/spreadsheets/d/1OiUKuuJhHXNmTr-KWYdVl7UapIgAbDuuf9w34hbQNFU/edit#gid=0"
).sheet1

BOT_TOKEN = "7645593337:AAHWs1_kIdpUBZkdQxKd_OcN9IEzTC7umVs"

def parse_cian(url):
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from bs4 import BeautifulSoup
    import logging
    import re
    import json

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-software-rasterizer")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1920,1080")
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)

    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.get("https://spb.cian.ru")

        try:
            with open("cookies_cian.json", "r", encoding="utf-8") as f:
                cookies = json.load(f)
                for cookie in cookies:
                    if "domain" in cookie and not (
                        "cian.ru" in cookie["domain"] or "spb.cian.ru" in cookie["domain"]
                    ):
                        continue
                    try:
                        driver.add_cookie(cookie)
                    except Exception as ce:
                        logging.debug(f"‚õî –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è cookie {cookie.get('name')}: {ce}")
            logging.info("‚úÖ –ö—É–∫–∏ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –±—Ä–∞—É–∑–µ—Ä")
        except Exception as e:
            logging.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—É–∫–∏: {e}")

        driver.get(url)
        wait = WebDriverWait(driver, 10)
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        soup = BeautifulSoup(driver.page_source, "html.parser")

        def extract_text(selector):
            el = soup.select_one(selector)
            return el.get_text(strip=True) if el else None

        title = extract_text("h1[class*='--title--']")
        price_raw = extract_text('[data-testid="price-amount"]')
        price = re.sub(r"[^\d]", "", price_raw or "")

        address_parts = soup.select('a[data-name="AddressItem"]')
        address_texts = [a.get_text(strip=True) for a in address_parts]
        address = ", ".join(address_texts)
        district = next((x for x in address_texts if "—Ä-–Ω" in x), None)

        # –ü–ª–æ—â–∞–¥—å
        area = None
        for div in soup.select('div[data-name="OfferSummaryInfoItem"]'):
            label = div.select_one("p")
            if label and "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å" in label.text:
                value = div.select("p")[1].get_text(strip=True)
                area_match = re.search(r"\d+([.,]\d+)?", value)
                if area_match:
                    area = float(area_match.group(0).replace(",", "."))

        # –≠—Ç–∞–∂
        floor = None
        floor_match = soup.find("span", string=re.compile(r"\d+\s+–∏–∑\s+\d+"))
        if floor_match:
            floor = floor_match.get_text(strip=True)

        # –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏
        year = None
        year_tag = soup.find("p", string=re.compile(r"^\d{4}$"))
        if year_tag:
            try:
                y_val = int(year_tag.text.strip())
                if 1800 <= y_val <= 2100:
                    year = y_val
            except:
                pass

        # –ë–∞–ª–∫–æ–Ω
        balcony = None
        balcony_tag = soup.find("p", string=re.compile(r"–±–∞–ª–∫–æ–Ω", re.IGNORECASE))
        if balcony_tag:
            balcony = balcony_tag.get_text(strip=True)

        return {
            "title": title,
            "address": address,
            "district": district,
            "area": area,
            "year": year,
            "price": price,
            "url": url,
            "balcony": balcony,
            "floor": floor,
            "source": "CIAN-Selenium"
        }

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ CIAN —á–µ—Ä–µ–∑ Selenium –¥–ª—è {url}: {e}")
        return None
    finally:
        if driver:
            driver.quit()

# ===========================
# parse_avito
# ===========================
def parse_avito(url: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç Avito:
    - –ù–∞–∑–≤–∞–Ω–∏–µ (title)
    - –ê–¥—Ä–µ—Å (–±–µ–∑ '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, ')
    - –†–∞–π–æ–Ω (–ø–æ –±–ª–æ–∫—É '—Ä-–Ω –ü—Ä–∏–º–æ—Ä—Å–∫–∏–π')
    - –ü–ª–æ—â–∞–¥—å (–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å)
    - –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏
    - –ë–∞–ª–∫–æ–Ω
    - –≠—Ç–∞–∂
    - –¶–µ–Ω–∞
    - –ò—Å—Ö–æ–¥–Ω–∞—è —Å—Å—ã–ª–∫–∞ (url)
    """

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1920,1080")
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)

    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)

        wait = WebDriverWait(driver, 10)

        # 1) –ù–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ç–∞–π—Ç–ª–∞:
        title = driver.title
        if "|" in title:
            title = title.split("|")[0].strip()

        # 2) –¶–µ–Ω–∞
        price = None
        try:
            price_el = driver.find_element(By.CSS_SELECTOR, '[itemprop="price"]')
            price = price_el.get_attribute("content")
        except Exception:
            logging.warning("–ù–µ –Ω–∞—à–ª–∏ price –≤ itemprop='price' - fallback –Ω–∏–∂–µ")

        # –ë—É–¥–µ–º –∏—Å–∫–∞—Ç—å –∞–¥—Ä–µ—Å –∏ —Ä–∞–π–æ–Ω
        address = None
        district = None

        # 3) –ê–¥—Ä–µ—Å
        try:
            # –≠–ª–µ–º–µ–Ω—Ç —Å –∞–¥—Ä–µ—Å–æ–º: <span class="style-item-address__string-wt61A">
            address_el = driver.find_element(By.CSS_SELECTOR, ".style-item-address__string-wt61A")
            address = address_el.text.strip()
            # –£–±–∏—Ä–∞–µ–º "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, " –µ—Å–ª–∏ –µ—Å—Ç—å
            if address.startswith("–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, "):
                address = address.replace("–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, ", "").strip()
        except Exception as e:
            logging.warning(f"–ê–¥—Ä–µ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")

        # 4) –†–∞–π–æ–Ω
        try:
            # –ë–ª–æ–∫: <span class="style-item-address-georeferences-item-TZsrp">
            # –í–Ω—É—Ç—Ä–∏ –µ—â—ë <span>—Ä-–Ω –ü—Ä–∏–º–æ—Ä—Å–∫–∏–π</span>
            district_el = driver.find_element(By.CSS_SELECTOR, ".style-item-address-georeferences-item-TZsrp span:nth-child(2)")
            district = district_el.text.strip()  # –ù–∞–ø—Ä–∏–º–µ—Ä: "—Ä-–Ω –ü—Ä–∏–º–æ—Ä—Å–∫–∏–π"
        except Exception as e:
            logging.warning(f"–†–∞–π–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        area = None
        floor = None
        balcony = None
        year = None

        # –î–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        re_area = r"\d+(?:[.,]\d+)?"
        re_floor = r"(\d+\s*–∏–∑\s*\d+)|(\d+/\d+)"

        try:
            # –û–∂–∏–¥–∞–µ–º <li>, —á–µ–π –∫–ª–∞—Å—Å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ "params-paramsList__item"
            wait.until(EC.presence_of_all_elements_located(
                (By.CSS_SELECTOR, "li[class^='params-paramsList__item']")
            ))
            all_params = driver.find_elements(By.CSS_SELECTOR, "li[class^='params-paramsList__item']")

            if all_params:
                for item in all_params:
                    text = item.text.strip()
                    logging.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä: {text}")

                    # –û–±—â–∞—è –ø–ª–æ—â–∞–¥—å
                    if "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å" in text:
                        match = re.search(re_area, text)
                        if match:
                            area_val = match.group(0).replace(",", ".")
                            area = float(area_val)

                    # –ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏ –∏–ª–∏ –ì–æ–¥ —Å–¥–∞—á–∏
                    elif "–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏" in text or "–ì–æ–¥ —Å–¥–∞—á–∏" in text:
                        match = re.search(r"\d{4}", text)
                        if match:
                            y = int(match.group())
                            if 1800 <= y <= 2050:
                                year = y

                    # –ë–∞–ª–∫–æ–Ω
                    elif "–ë–∞–ª–∫–æ–Ω" in text:
                        text_low = text.lower()
                        if "–Ω–µ—Ç" in text_low:
                            balcony = "–Ω–µ—Ç"
                        elif "–µ—Å—Ç—å" in text_low or re.search(r"\d+", text_low):
                            balcony = "–µ—Å—Ç—å"
                        else:
                            parts = text.split(":")
                            if len(parts) > 1:
                                balcony = parts[1].strip()

                    # –≠—Ç–∞–∂
                    elif "–≠—Ç–∞–∂" in text:
                        fm = re.search(re_floor, text)
                        if fm:
                            floor = fm.group(0)  # "6 –∏–∑ 24" –∏–ª–∏ "6/24"
                        else:
                            # fallback: –±–µ—Ä–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                            parts = text.split(":")
                            if len(parts) > 1:
                                floor = parts[1].strip()

            else:
                logging.warning("–ù–µ –Ω–∞—à–ª–∏ params-paramsList__item —á–µ—Ä–µ–∑ Selenium, –ø—Ä–æ–±—É–µ–º BS fallback")

                soup = BeautifulSoup(driver.page_source, "html.parser")
                param_items = soup.find_all("li", class_=re.compile(r"params-paramsList__item"))

                for li_ in param_items:
                    text = li_.get_text(strip=True)
                    logging.info(f"[BS] –ü–∞—Ä–∞–º–µ—Ç—Ä: {text}")

                    if "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å" in text:
                        m = re.search(re_area, text)
                        if m:
                            area = float(m.group(0).replace(",", "."))
                    elif "–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏" in text or "–ì–æ–¥ —Å–¥–∞—á–∏" in text:
                        m = re.search(r"\d{4}", text)
                        if m:
                            y = int(m.group())
                            if 1800 <= y <= 2050:
                                year = y
                    elif "–ë–∞–ª–∫–æ–Ω" in text:
                        if "–Ω–µ—Ç" in text.lower():
                            balcony = "–Ω–µ—Ç"
                        elif "–µ—Å—Ç—å" in text.lower() or re.search(r"\d+", text.lower()):
                            balcony = "–µ—Å—Ç—å"
                        else:
                            parts = text.split(":")
                            if len(parts) > 1:
                                balcony = parts[1].strip()
                    elif "–≠—Ç–∞–∂" in text:
                        fm = re.search(re_floor, text)
                        if fm:
                            floor = fm.group(0)

        except Exception as e:
            logging.warning(f"–û—à–∏–±–∫–∞ Selenium –≤ –±–ª–æ–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}, –ø—Ä–æ–±—É–µ–º BS fallback")
            soup = BeautifulSoup(driver.page_source, "html.parser")
            param_items = soup.find_all("li", class_=re.compile(r"params-paramsList__item"))
            for li_ in param_items:
                text = li_.get_text(strip=True)
                # ... –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø–∞—Ä—Å–∏–º

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥:
        result = {
            "title": title,          # "1-–∫. –∫–≤–∞—Ä—Ç–∏—Ä–∞, 34 –º¬≤, 6/24 —ç—Ç. ..."
            "price": price,          # "7299000"
            "area": area,            # float (e.g. 34.5)
            "year": year,            # int (e.g. 1975)
            "balcony": balcony,      # "–µ—Å—Ç—å" / "–Ω–µ—Ç" / ...
            "floor": floor,          # "6 –∏–∑ 24" / "6/24" / ...
            "address": address,      # e.g. "–ü–ª–∞–Ω–µ—Ä–Ω–∞—è —É–ª., 97–∫2"
            "district": district,    # e.g. "—Ä-–Ω –ü—Ä–∏–º–æ—Ä—Å–∫–∏–π"
            "url": url               # —Å–∞–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
        }
        return result

    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Avito –¥–ª—è {url}: {e}")
        return None

    finally:
        if driver:
            driver.quit()


# ------------------------------------------------------
# –ü–†–û–í–ï–†–ö–ê –ù–ê –î–£–ë–õ–ò–ö–ê–¢ (—á—Ç–æ–±—ã –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å –ø–æ–≤—Ç–æ—Ä)
# ------------------------------------------------------

def is_duplicate_link(sheet, link: str) -> bool:
    """
    –°—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ (–∏–ª–∏ –≤—Å–µ —è—á–µ–π–∫–∏),
    –≥–¥–µ –º—ã –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å —Ñ–æ—Ä–º—É–ª—É –≤–∏–¥–∞ =HYPERLINK("link"; "title").
    –ï—Å–ª–∏ 'link' —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ —è—á–µ–π–∫–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–º.
    """
    all_rows = sheet.get_all_values()  # –°–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤
    for row in all_rows:
        # row[0] - —ç—Ç–æ –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ (–≥–¥–µ –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –Ω–∞—à–∞ —Ñ–æ—Ä–º—É–ª–∞)
        if len(row) > 0 and link in row[0]:
            return True
    return False
    
# ------------------------------------------------------
# 2) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–ê–Ø –ö–û–ú–ê–ù–î–ê /table
# ------------------------------------------------------

async def table_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ü—Ä–∏–º–µ—Ä: –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—É—â–µ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–∞–±–ª–∏—Ü—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ HTML.
    """
    values = sheet.get_all_values()  # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫)
    # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π HTML <table>:
    html = ["<b>–¢–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ:</b>", "<table border='1' cellspacing='0' cellpadding='3'>"]
    
    # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–∞—à–µ–π —Ç–∞–±–ª–∏—Ü—ã)
    # –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π —à–∞–ø–∫–∏, –º–æ–∂–Ω–æ –≤—ã–≤–æ–¥–∏—Ç—å –≤—Å—ë:
    for row in values:
        html.append("<tr>")
        for col in row:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∞–º–ø–µ—Ä—Å–∞–Ω–¥—ã –∏ —Ç.–ø. –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏
            cell_text = col.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
            html.append(f"<td>{cell_text}</td>")
        html.append("</tr>")

    html.append("</table>")

    html_str = "\n".join(html)
    await update.message.reply_text(html_str, parse_mode="HTML")

# ------------------------------------------------------
# –û–ë–†–ê–ë–û–¢–ö–ê –°–û–û–ë–©–ï–ù–ò–ô (—Å—Å—ã–ª–æ–∫)
# ------------------------------------------------------
    
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å —Å—Å—ã–ª–∫—É –Ω–∞ Avito –∏–ª–∏ CIAN")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text.strip()
    url = user_message
    chat_id = update.message.chat_id

    logging.info(f"–ë–æ—Ç –ø–æ–ª—É—á–∏–ª —Å—Å—ã–ª–∫—É: {user_message}")
    await update.message.reply_text("üì© –°—Å—ã–ª–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞! –°–µ–π—á–∞—Å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é‚Ä¶")

    if "avito.ru" in url:
        data = parse_avito(url)
    elif "cian.ru" in url:
        data = parse_cian(url)
    else:
        await update.message.reply_text("–≠—Ç–æ –Ω–µ —Å—Å—ã–ª–∫–∞ –Ω–∞ Avito –∏–ª–∏ CIAN")
        return

    if not data:
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Å—ã–ª–∫—É.")
        return
# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç –ª–∏
    if is_duplicate_link(sheet, data["url"]):
        await update.message.reply_text("‚ö†Ô∏è –ü–æ—Ö–æ–∂–µ, —Ç–∞–∫–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —É–∂–µ –µ—Å—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ!")
        return
# –ï—Å–ª–∏ –∫–∞–∫–æ–≥–æ-—Ç–æ –ø–æ–ª—è –Ω–µ—Ç, –ø–æ–¥—Å—Ç–∞–≤–∏–º –∑–∞–≥–ª—É—à–∫—É
    floor_value = data.get("floor", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")

    message = (
        f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Ç–∞–±–ª–∏—Ü—É!\n"
        f"üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {data.get('title', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')}\n"
        f"üè° –ê–¥—Ä–µ—Å: {data.get('address', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')}\n"
        f"üìç –†–∞–π–æ–Ω: {data.get('district', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')}\n"
        f"üìê –ü–ª–æ—â–∞–¥—å: {data.get('area', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')} –º¬≤\n"
        f"üï∞ –ì–æ–¥: {data.get('year', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n"
        f"üí∞ –¶–µ–Ω–∞: {data.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')} ‚ÇΩ\n"
        f"ü™ü –ë–∞–ª–∫–æ–Ω: {data.get('balcony', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n"
        f"üè¢ –≠—Ç–∞–∂: {floor_value}\n"
    )

    await update.message.reply_text(message)
 
 # 2) –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É
    try:
        sheet.append_row([
            hyperlink_formula,            # 1) –ù–∞–∑–≤–∞–Ω–∏–µ-—Å—Å—ã–ª–∫–∞
#data.get("title", ""),
            data.get("address", ""),
            data.get("district", ""),
            data.get("area", ""),
            data.get("year", ""),
            data.get("price", ""),
#data.get("url", ""),
            data.get("balcony", ""),
            floor_value,
            ""  # –º–µ—Å—Ç–æ –ø–æ–¥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        ])
    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ç–∞–±–ª–∏—Ü—É –¥–ª—è {url}: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ Google –¢–∞–±–ª–∏—Ü—É :(")

def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("table", table_command))  # /table
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
